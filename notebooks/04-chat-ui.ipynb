{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Load initial libraries and config to get things up an running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "template = \"\"\"Answer the question based on the context below. Keep the answer short. Use two sentences maxiumum. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "vectordb = Chroma(\n",
    "    persist_directory=\"../vectors/\",\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "question_answerer = ConversationalRetrievalChain.from_llm(\n",
    "    ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0),\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    combine_docs_chain_kwargs={\"prompt\": PromptTemplate.from_template(template)},\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot Layout\n",
    "Setup an interface to interact with the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from ipywidgets import widgets\n",
    "\n",
    "def text_eventhandler(*event):\n",
    "    if event[0][\"new\"] == \"\":\n",
    "        return\n",
    "\n",
    "    loading_bar.layout.display = \"block\"\n",
    "\n",
    "    question = event[0][\"new\"]\n",
    "\n",
    "    event[0][\"owner\"].value = \"\"\n",
    "\n",
    "    question_chat_bubble = (\n",
    "        f'<div class=\"chat-message-right pb-4\"><div>'\n",
    "        + f'<div class=\"flex-shrink-1 bg-light rounded py-2 px-3 ml-3\">'\n",
    "        + f'<div class=\"font-weight-bold mb-1\">You</div>{question}</div>'\n",
    "    )\n",
    "\n",
    "    output.append_display_data(HTML(question_chat_bubble))\n",
    "\n",
    "    try:\n",
    "        response = question_answerer({\"question\": f\"{question}\"})\n",
    "        answer = response[\"answer\"]\n",
    "    except Exception as e:\n",
    "        answer = \"<b>Error:</b> \" + str(e)\n",
    "\n",
    "    answer_chat_bubble = (\n",
    "        f'<div class=\"chat-message-left pb-4\"><div>'\n",
    "        + f'<div class=\"flex-shrink-1 bg-primary text-white rounded py-2 px-3 ml-3\">'\n",
    "        + f'<div class=\"font-weight-bold text-white mb-1\">Malina Bot</div>{answer}</div>'\n",
    "    )\n",
    "\n",
    "    loading_bar.layout.display = \"none\"\n",
    "\n",
    "    output.append_display_data(HTML(answer_chat_bubble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<link rel=\"stylesheet\" \n",
    "      href=\"https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css\" \n",
    "      integrity=\"sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2\" \n",
    "      crossorigin=\"anonymous\">\n",
    "<style>\n",
    "    body {\n",
    "        background-color: #21222B;\n",
    "        margin-top:20px;\n",
    "    }\n",
    "\n",
    "    .bg-primary {\n",
    "        background-color: #ee3f6e !important;\n",
    "    }\n",
    "\n",
    "    .chat-message-left,\n",
    "    .chat-message-right {\n",
    "        display: flex;\n",
    "        flex-shrink: 0\n",
    "    }\n",
    "\n",
    "    .chat-message-left {\n",
    "        margin-right: auto\n",
    "    }\n",
    "\n",
    "    .chat-message-right {\n",
    "        flex-direction: row-reverse;\n",
    "        margin-left: auto\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "text_input = widgets.Text()\n",
    "text_input.continuous_update = False\n",
    "text_input.observe(text_eventhandler, \"value\")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "load_image = open(\"../images/loading.gif\", \"rb\")\n",
    "loading_bar = widgets.Image(\n",
    "    value=load_image.read(), \n",
    "    format=\"gif\", \n",
    "    width=\"20\", \n",
    "    height=\"20\", \n",
    "    layout={ \"display\": \"None\" }\n",
    ")\n",
    "\n",
    "display(\n",
    "    widgets.HBox(\n",
    "        [output],\n",
    "        layout=widgets.Layout(\n",
    "            width=\"100%\",\n",
    "            display=\"inline-flex\",\n",
    "            flex_flow=\"column-reverse\",\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "display(\n",
    "    widgets.Box(\n",
    "        children=[loading_bar, text_input],\n",
    "        layout=widgets.Layout(display=\"flex\", flex_flow=\"row\"),\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
